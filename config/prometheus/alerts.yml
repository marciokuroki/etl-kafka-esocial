# config/prometheus/alerts.yml
# Regras de Alerta - Pipeline ETL eSocial com Apache Kafka
# Vers√£o: 2.0 - Consolidada
# √öltima atualiza√ß√£o: 2025-11-22

groups:
  # ========================================
  # GRUPO 1: ALERTAS CR√çTICOS DO PRODUCER
  # ========================================
  - name: producer_critical_alerts
    interval: 30s
    rules:
      
      # Servi√ßo Producer Indispon√≠vel
      - alert: ProducerServiceDown
        expr: |
          up{job="producer-service"} == 0
        for: 1m
        labels:
          severity: critical
          component: producer
          category: availability
          team: platform
        annotations:
          summary: "üö® Producer Service indispon√≠vel"
          description: |
            O Producer Service n√£o est√° respondendo h√° mais de 1 minuto.
            Status: DOWN
            Job: {{ $labels.job }}
            Instance: {{ $labels.instance }}
          action: |
            1. Verificar status do container:
               docker ps -a | grep producer-service
            
            2. Ver logs recentes:
               docker logs esocial-producer --tail 100
            
            3. Verificar conectividade com depend√™ncias:
               - PostgreSQL: docker exec esocial-postgres-db pg_isready
               - Kafka: curl http://localhost:8090/api/clusters
            
            4. Reiniciar servi√ßo:
               docker-compose restart producer-service
          runbook_url: "https://github.com/marciokuroki/etl-kafka-esocial/wiki/Runbook-ProducerServiceDown"

      # Alta Taxa de Erro no Producer
      - alert: ProducerHighErrorRate
        expr: |
          rate(events_failed_total{service="producer"}[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
          component: producer
          category: data-quality
          team: data-engineering
        annotations:
          summary: "‚ö†Ô∏è Producer com alta taxa de erro"
          description: |
            Taxa de erro no Producer est√° em {{ $value | humanizePercentage }}.
            Limite: 5%
            Servi√ßo: Producer Service
          action: |
            1. Consultar m√©tricas detalhadas:
               curl http://localhost:8081/actuator/prometheus | grep events_failed
            
            2. Verificar logs de erro:
               docker logs esocial-producer --tail 50 | grep ERROR
            
            3. Verificar conectividade com banco de origem:
               docker exec esocial-postgres-db psql -U esocial_user -d esocial -c "SELECT 1;"
            
            4. Analisar √∫ltimas mudan√ßas no schema da origem
          runbook_url: "https://github.com/marciokuroki/etl-kafka-esocial/wiki/Runbook-ProducerHighErrorRate"

      # CDC com Lat√™ncia Elevada
      - alert: CDCHighLatency
        expr: |
          histogram_quantile(0.95, rate(cdc_polling_duration_seconds_bucket{service="producer"}[5m])) > 10
        for: 5m
        labels:
          severity: warning
          component: producer-cdc
          category: performance
          team: data-engineering
        annotations:
          summary: "‚è±Ô∏è CDC com lat√™ncia elevada"
          description: |
            Lat√™ncia P95 do CDC est√° em {{ $value }}s.
            Limite: 10 segundos
            Poss√≠vel gargalo no polling ou no banco de dados.
          action: |
            1. Verificar carga do PostgreSQL:
               docker exec esocial-postgres-db psql -U esocial_user -d esocial -c "SELECT * FROM pg_stat_activity WHERE state = 'active';"
            
            2. Analisar volume de mudan√ßas:
               docker exec esocial-postgres-db psql -U esocial_user -d esocial -c "SELECT COUNT(*) FROM source.employees WHERE updated_at > NOW() - INTERVAL '5 minutes';"
            
            3. Verificar configura√ß√£o de polling interval
            
            4. Considerar otimizar queries do CDC
          runbook_url: "https://github.com/marciokuroki/etl-kafka-esocial/wiki/Runbook-CDCHighLatency"

      # Throughput Baixo no Producer
      - alert: ProducerLowThroughput
        expr: |
          rate(events_published_total{service="producer"}[5m]) * 60 < 1
        for: 10m
        labels:
          severity: warning
          component: producer
          category: performance
          team: data-engineering
        annotations:
          summary: "üìâ Throughput baixo no Producer"
          description: |
            Producer publicando apenas {{ $value }} eventos/min.
            Esperado: > 1 evento/min
          action: |
            1. Verificar se h√° dados novos na origem
            2. Analisar lat√™ncia do CDC
            3. Verificar conectividade com Kafka
          runbook_url: "https://github.com/marciokuroki/etl-kafka-esocial/wiki/Runbook-LowThroughput"

  # ========================================
  # GRUPO 2: ALERTAS CR√çTICOS DO CONSUMER
  # ========================================
  - name: consumer_critical_alerts
    interval: 30s
    rules:
      
      # Servi√ßo Consumer Indispon√≠vel
      - alert: ConsumerServiceDown
        expr: |
          up{job="consumer-service"} == 0
        for: 1m
        labels:
          severity: critical
          component: consumer
          category: availability
          team: platform
        annotations:
          summary: "üö® Consumer Service indispon√≠vel"
          description: |
            O Consumer Service n√£o est√° respondendo.
            Status: DOWN
            Job: {{ $labels.job }}
          action: |
            1. Verificar container:
               docker ps -a | grep consumer-service
            
            2. Ver logs:
               docker logs esocial-consumer --tail 100
            
            3. Verificar depend√™ncias:
               - Kafka: curl http://localhost:8090
               - PostgreSQL: docker exec esocial-postgres-db pg_isready
            
            4. Reiniciar:
               docker-compose restart consumer-service
          runbook_url: "https://github.com/marciokuroki/etl-kafka-esocial/wiki/Runbook-ConsumerServiceDown"

      # Alta Taxa de Erro de Valida√ß√£o
      - alert: ConsumerHighValidationErrorRate
        expr: |
          (
            rate(validation_failure_total{service="consumer",severity="ERROR"}[5m]) 
            / 
            (rate(validation_success_total{service="consumer"}[5m]) + rate(validation_failure_total{service="consumer",severity="ERROR"}[5m]))
          ) > 0.05
        for: 5m
        labels:
          severity: critical
          component: consumer
          category: data-quality
          team: data-engineering
        annotations:
          summary: "‚ö†Ô∏è Alta taxa de erro de valida√ß√£o"
          description: |
            Taxa de falha nas valida√ß√µes: {{ $value | humanizePercentage }}.
            Limite: 5%
            Servi√ßo: Consumer Service
          action: |
            1. Consultar erros via API:
               curl http://localhost:8082/api/v1/validation/errors | jq
            
            2. Ver distribui√ß√£o de erros:
               curl http://localhost:8082/api/v1/validation/dashboard | jq
            
            3. Verificar logs:
               docker logs esocial-consumer --tail 100 | grep "Validation failed"
            
            4. Analisar padr√£o de erros para identificar causa raiz
          runbook_url: "https://github.com/marciokuroki/etl-kafka-esocial/wiki/Runbook-HighValidationErrorRate"

      # DLQ Acumulando (Warning)
      - alert: DLQAccumulating
        expr: |
          dlq_events_pending{service="consumer"} > 100
        for: 10m
        labels:
          severity: warning
          component: consumer-dlq
          category: data-processing
          team: data-engineering
        annotations:
          summary: "üì¨ DLQ com eventos acumulados"
          description: |
            {{ $value }} eventos acumulados na Dead Letter Queue.
            Limite Warning: 100 eventos
            Requer aten√ß√£o para evitar ac√∫mulo cr√≠tico.
          action: |
            1. Consultar eventos DLQ:
               curl http://localhost:8082/api/v1/validation/dlq | jq
            
            2. Analisar padr√µes de erro:
               curl http://localhost:8082/api/v1/validation/dlq | jq '.[] | .errorMessage' | sort | uniq -c
            
            3. Verificar se causa raiz j√° foi corrigida
            
            4. Considerar reprocessamento em lote
          runbook_url: "https://github.com/marciokuroki/etl-kafka-esocial/wiki/Runbook-DLQAccumulating"

      # DLQ Cr√≠tica
      - alert: DLQCritical
        expr: |
          dlq_events_pending{service="consumer"} > 500
        for: 5m
        labels:
          severity: critical
          component: consumer-dlq
          category: data-processing
          team: data-engineering
        annotations:
          summary: "üö® DLQ CR√çTICA - Muitos eventos pendentes"
          description: |
            {{ $value }} eventos na DLQ - situa√ß√£o cr√≠tica!
            Limite Critical: 500 eventos
            Requer interven√ß√£o IMEDIATA.
          action: |
            1. URGENTE: Consultar eventos DLQ:
               curl http://localhost:8082/api/v1/validation/dlq | jq
            
            2. Identific
