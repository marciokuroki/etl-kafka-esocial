# Pipeline ETL eSocial com Apache Kafka

[![Status](https://img.shields.io/badge/status-Sprint%201%20Complete-brightgreen)]()
[![Build](https://img.shields.io/badge/build-passing-brightgreen)]()
[![Coverage](https://img.shields.io/badge/coverage-82%25-brightgreen)]()
[![License](https://img.shields.io/badge/license-TCC-blue)]()

SoluÃ§Ã£o de streaming de dados event-driven para integraÃ§Ã£o com o eSocial utilizando Apache Kafka, Spring Boot e PostgreSQL.

## ğŸ“‹ Ãndice

- [Sobre o Projeto](#sobre-o-projeto)
- [Status do Projeto](#status-do-projeto)
- [Arquitetura](#arquitetura)
- [Funcionalidades](#funcionalidades)
- [Tecnologias](#tecnologias)
- [PrÃ©-requisitos](#prÃ©-requisitos)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Uso](#uso)
- [Testes](#testes)
- [DocumentaÃ§Ã£o](#documentaÃ§Ã£o)
- [Roadmap](#roadmap)
- [ContribuiÃ§Ã£o](#contribuiÃ§Ã£o)
- [LicenÃ§a](#licenÃ§a)
- [Contato](#contato)

---

## ğŸ“– Sobre o Projeto

O **Pipeline ETL eSocial** Ã© uma soluÃ§Ã£o completa de streaming de dados que captura mudanÃ§as em sistemas de RH, valida conforme regras do eSocial e prepara dados para envio ao portal governamental.

### Contexto

O eSocial Ã© um sistema do governo federal que unifica a prestaÃ§Ã£o de informaÃ§Ãµes trabalhistas. Este projeto implementa um pipeline ETL robusto e escalÃ¡vel para automatizar o envio de dados ao eSocial, garantindo:

- âœ… **Conformidade** com regras do eSocial
- âœ… **Rastreabilidade** completa (audit trail)
- âœ… **Escalabilidade** horizontal
- âœ… **ResiliÃªncia** (zero perda de dados)
- âœ… **Observabilidade** em tempo real

### PropÃ³sito AcadÃªmico

Este projeto faz parte do Trabalho de ConclusÃ£o de Curso (TCC) da PÃ³s-GraduaÃ§Ã£o em Arquitetura de Software e SoluÃ§Ãµes pela XP EducaÃ§Ã£o.

**Orientador:** Reinaldo GalvÃ£o  
**Aluno:** MÃ¡rcio Kuroki GonÃ§alves  
**Ano:** 2025

---

## ğŸš€ Status do Projeto

### Sprint 1 - âœ… ConcluÃ­da (100%)

**PerÃ­odo:** 01/11/2025 - 30/11/2025

| ServiÃ§o | Status | Build | Testes | Coverage | Funcionalidades |
|---------|--------|-------|--------|----------|-----------------|
| **Producer Service** | âœ… Completo | âœ… Passing | 18/18 | 82% | CDC + Kafka Producer |
| **Consumer Service** | âœ… Completo | âœ… Passing | - | - | Validation + Persistence + API |
| **Kafka Cluster** | âœ… Operacional | - | - | - | 3 brokers, 4 topics |
| **PostgreSQL** | âœ… Configurado | - | - | - | Origem + Destino + Audit |
| **Observabilidade** | âœ… Funcionando | - | - | - | Prometheus + Grafana |
| **DocumentaÃ§Ã£o** | âœ… Completa | - | - | - | C4 Model + 5 ADRs |

### PrÃ³ximas Sprints

- ğŸ”„ **Sprint 2** (em planejamento): Testes + Dashboards + Swagger
- ğŸ“‹ **Sprint 3** (backlog): CI/CD + ProduÃ§Ã£o

---

## ğŸ—ï¸ Arquitetura

### VisÃ£o Geral

```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sistema RH â”‚ --> â”‚ Producer Svc â”‚ --> â”‚   Kafka     â”‚
â”‚  (Origem)   â”‚     â”‚  (CDC+Pub)   â”‚     â”‚  (Broker)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
                                                â–¼
                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                         â”‚ Consumer Svc â”‚
                                         â”‚ (Valid+Pers) â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
                                                â–¼
                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                         â”‚ PostgreSQL   â”‚
                                         â”‚ (Destino)    â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes

| Componente | Tecnologia | Porta | FunÃ§Ã£o |
|------------|-----------|-------|--------|
| Producer Service | Spring Boot 3.2 | 8081 | Change Data Capture + PublicaÃ§Ã£o Kafka |
| Consumer Service | Spring Boot 3.2 | 8082 | Consumo + ValidaÃ§Ã£o + PersistÃªncia + API |
| Kafka Cluster | Confluent 7.5 | 9092-9094 | Message Broker (3 brokers) |
| Zookeeper | Apache 3.8 | 2181 | CoordenaÃ§Ã£o Kafka |
| PostgreSQL Origem | PostgreSQL 15 | 5432 | Sistema legado (simulado) |
| PostgreSQL Destino | PostgreSQL 15 | 5432 | Dados processados |
| Prometheus | Prometheus 2.45 | 9090 | Coleta de mÃ©tricas |
| Grafana | Grafana 10.0 | 3000 | Dashboards |
| Kafka UI | Provectus | 8090 | Interface Kafka |
| PgAdmin | PgAdmin 4 | 5050 | Admin PostgreSQL |

**DocumentaÃ§Ã£o completa:** [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md)

---

## âœ¨ Funcionalidades

### âœ… Implementado (Sprint 1)

#### Producer Service
- [x] Change Data Capture via polling (5s)
- [x] DetecÃ§Ã£o automÃ¡tica de tipo de evento (CREATE/UPDATE/DELETE)
- [x] PublicaÃ§Ã£o em tÃ³picos Kafka separados por tipo
- [x] MÃ©tricas Prometheus
- [x] Health checks
- [x] 18 testes unitÃ¡rios (82% coverage)

#### Consumer Service
- [x] Consumo de eventos Kafka (3 tÃ³picos)
- [x] ValidaÃ§Ã£o em 2 camadas (estrutural + negÃ³cio)
  - [x] 6 regras estruturais (formato, obrigatoriedade)
  - [x] 5 regras de negÃ³cio (idade, datas, salÃ¡rio)
- [x] PersistÃªncia com versionamento
- [x] Audit trail completo
- [x] Dead Letter Queue (DLQ)
- [x] API REST para relatÃ³rios
  - [x] `GET /api/v1/validation/errors` - Erros de validaÃ§Ã£o
  - [x] `GET /api/v1/validation/dashboard` - Dashboard
  - [x] `GET /api/v1/validation/dlq` - Eventos DLQ
- [x] MÃ©tricas Prometheus
- [x] Health checks

#### Infraestrutura
- [x] Cluster Kafka (3 brokers, RF=3)
- [x] 4 tÃ³picos com 3 partiÃ§Ãµes cada
- [x] PostgreSQL com schemas separados (source, public, audit)
- [x] Stack de observabilidade completa
- [x] Docker Compose (14 containers)
- [x] Scripts de automaÃ§Ã£o

#### DocumentaÃ§Ã£o
- [x] Arquitetura C4 Model (3 nÃ­veis)
- [x] 5 ADRs (Architectural Decision Records)
- [x] READMEs tÃ©cnicos (Producer e Consumer)
- [x] Guias de setup e troubleshooting

### ğŸ”„ Roadmap (PrÃ³ximas Sprints)

#### Sprint 2 - Qualidade e Observabilidade
- [ ] Testes de integraÃ§Ã£o (Testcontainers)
- [ ] Testes de carga (JMeter)
- [ ] Dashboards Grafana customizados
- [ ] Alertas Prometheus
- [ ] DocumentaÃ§Ã£o Swagger/OpenAPI
- [ ] Testes unitÃ¡rios Consumer (35+ testes)

#### Sprint 3 - ProduÃ§Ã£o
- [ ] CI/CD pipeline (GitHub Actions)
- [ ] MigraÃ§Ã£o CDC para Debezium
- [ ] SeguranÃ§a (TLS, SASL)
- [ ] Backup e recuperaÃ§Ã£o
- [ ] DocumentaÃ§Ã£o de deployment
- [ ] Testes end-to-end

---

## ğŸ› ï¸ Tecnologias

### Backend
- **Java 21** - Linguagem
- **Spring Boot 3.2.0** - Framework
- **Spring Kafka 3.1.0** - IntegraÃ§Ã£o Kafka
- **Spring Data JPA** - PersistÃªncia
- **Lombok** - ReduÃ§Ã£o de boilerplate

### Message Broker
- **Apache Kafka 3.5** - Message broker
- **Zookeeper 3.8** - CoordenaÃ§Ã£o

### Banco de Dados
- **PostgreSQL 15** - Banco relacional
- **HikariCP** - Connection pooling

### Observabilidade
- **Prometheus 2.45** - MÃ©tricas
- **Grafana 10.0** - Dashboards
- **Micrometer** - API de mÃ©tricas
- **SLF4J + Logback** - Logs

### DevOps
- **Docker** - ContainerizaÃ§Ã£o
- **Docker Compose** - OrquestraÃ§Ã£o local
- **Maven 3.9** - Build

### Testes
- **JUnit 5** - Framework de testes
- **Mockito** - Mocking
- **AssertJ** - Assertions fluentes
- **JaCoCo** - Cobertura de cÃ³digo
- **H2 Database** - Banco in-memory (testes)

### Ferramentas
- **Kafka UI** - Interface Kafka
- **PgAdmin 4** - Admin PostgreSQL
- **IntelliJ IDEA** - IDE

---

## ğŸ“‹ PrÃ©-requisitos

### ObrigatÃ³rios
- **Docker** 24.0+ e **Docker Compose** 2.20+
- **Git** 2.40+
- **8GB RAM** mÃ­nimo (16GB recomendado)
- **20GB** de espaÃ§o em disco

### Opcionais (para desenvolvimento)
- **Java 21** (OpenJDK ou Oracle JDK)
- **Maven 3.9+**
- **IntelliJ IDEA** ou **VS Code**

### Verificar InstalaÃ§Ã£o

```


# Docker

docker --version

# SaÃ­da esperada: Docker version 24.0.x

# Docker Compose

docker-compose --version

# SaÃ­da esperada: Docker Compose version 2.20.x

# Git

git --version

# SaÃ­da esperada: git version 2.40.x

```

---

## ğŸš€ InstalaÃ§Ã£o

### 1. Clonar o RepositÃ³rio

```

git clone https://github.com/seu-usuario/etl-kafka-esocial.git
cd etl-kafka-esocial

```

### 2. Configurar VariÃ¡veis de Ambiente (Opcional)

```


# Copiar arquivo de exemplo

cp .env.example .env

# Editar conforme necessÃ¡rio

vim .env

```

### 3. Compilar os ServiÃ§os (Opcional)

```


# Se quiser fazer alteraÃ§Ãµes no cÃ³digo

cd producer-service \&\& mvn clean package -DskipTests
cd ../consumer-service \&\& mvn clean package -DskipTests
cd ..

```

### 4. Iniciar Todos os Containers

```


# Iniciar infraestrutura completa

docker-compose up -d

# Aguardar containers ficarem healthy (~2 minutos)

docker-compose ps

# Ver logs em tempo real

docker-compose logs -f producer-service consumer-service

```

### 5. Validar InstalaÃ§Ã£o

```


# Health checks

curl http://localhost:8081/actuator/health | jq
curl http://localhost:8082/actuator/health | jq

# Acessar interfaces

# Kafka UI: http://localhost:8090

# Prometheus: http://localhost:9090

# Grafana: http://localhost:3000 (admin/admin)

```

**Status esperado:** Todos os serviÃ§os retornam `{"status":"UP"}`

---

## ğŸ’» Uso

### CenÃ¡rio 1: Inserir Novo Colaborador

```


# 1. Conectar no PostgreSQL

docker exec -it esocial-postgres-db psql -U esocial_user -d esocial

# 2. Inserir colaborador

INSERT INTO source.employees VALUES (
'EMP100',
'12345678901',
'10011223344',
'JoÃ£o da Silva Santos',
'1990-01-15',
'2024-01-10',
NULL,
'Analista de Sistemas',
'TI',
5500.00,
'ACTIVE',
NOW(),
NOW()
);

# 3. Aguardar 5 segundos (polling)

# 4. Verificar processamento

SELECT * FROM public.employees WHERE source_id = 'EMP100';
SELECT * FROM audit.employees_history WHERE source_id = 'EMP100';

```

**Resultado esperado:**
- âœ… Producer captura mudanÃ§a
- âœ… Evento publicado no Kafka (topic: employee-create)
- âœ… Consumer valida dados
- âœ… Registro persistido no destino
- âœ… HistÃ³rico criado na audit

### CenÃ¡rio 2: Atualizar SalÃ¡rio

```

-- Atualizar salÃ¡rio
UPDATE source.employees
SET salary = 6500.00, updated_at = NOW()
WHERE employee_id = 'EMP100';

-- Verificar versionamento
SELECT source_id, salary, version FROM public.employees
WHERE source_id = 'EMP100';

-- Ver histÃ³rico
SELECT operation, salary, version, changed_at
FROM audit.employees_history
WHERE source_id = 'EMP100'
ORDER BY changed_at;

```

**Resultado esperado:**
- âœ… Version incrementada (1 â†’ 2)
- âœ… HistÃ³rico com 2 registros (INSERT + UPDATE)

### CenÃ¡rio 3: Consultar Erros de ValidaÃ§Ã£o

```


# API REST

curl http://localhost:8082/api/v1/validation/errors | jq

# Dashboard

curl http://localhost:8082/api/v1/validation/dashboard | jq

# Dead Letter Queue

curl http://localhost:8082/api/v1/validation/dlq | jq

```

### CenÃ¡rio 4: Monitorar MÃ©tricas

```


# MÃ©tricas do Producer

curl http://localhost:8081/actuator/prometheus | grep events_published

# MÃ©tricas do Consumer

curl http://localhost:8082/actuator/prometheus | grep events_consumed

# Ou acessar dashboards

open http://localhost:9090  \# Prometheus
open http://localhost:3000  \# Grafana

```

---

## ğŸ§ª Testes

### Executar Testes do Producer

```

cd producer-service

# Todos os testes

mvn test

# Com relatÃ³rio de cobertura

mvn clean test

# Ver relatÃ³rio HTML

open target/site/jacoco/index.html

# Teste especÃ­fico

mvn test -Dtest=KafkaProducerServiceTest

```

**Resultado esperado:**
```

Tests run: 18, Failures: 0, Errors: 0, Skipped: 0
Coverage: 82%

```

### Executar Testes do Consumer (Sprint 2)

```

cd consumer-service
mvn test

```

### Testes de IntegraÃ§Ã£o (Sprint 2)

```


# Testes end-to-end

mvn verify -Pintegration-tests

```

---

## ğŸ“š DocumentaÃ§Ã£o

### DocumentaÃ§Ã£o TÃ©cnica

| Documento | DescriÃ§Ã£o | Link |
|-----------|-----------|------|
| **Arquitetura** | C4 Model completo (3 nÃ­veis) | [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) |
| **ADRs** | DecisÃµes arquiteturais (5 ADRs) | [docs/adr/](docs/adr/) |
| **Producer Service** | README tÃ©cnico | [producer-service/README.md](producer-service/README.md) |
| **Consumer Service** | README tÃ©cnico | [consumer-service/README.md](consumer-service/README.md) |
| **Testes - Producer** | Guia de testes | [producer-service/TESTING.md](producer-service/TESTING.md) |
| **Sprint 1** | Retrospectiva e evidÃªncias | [docs/sprint1/](docs/sprint1/) |

### Guias de Setup

- [Setup Docker Compose](docs/sprint1/setup/docker-compose-setup.md)
- [Setup Kafka Cluster](docs/sprint1/setup/kafka-cluster-setup.md)
- [Setup PostgreSQL](docs/sprint1/setup/postgres-setup.md)
- [Troubleshooting](docs/sprint1/lessons-learned/)

### APIs REST

#### Producer Service
- `GET /actuator/health` - Health check
- `GET /actuator/prometheus` - MÃ©tricas
- `GET /actuator/info` - InformaÃ§Ãµes da aplicaÃ§Ã£o

#### Consumer Service
- `GET /actuator/health` - Health check
- `GET /actuator/prometheus` - MÃ©tricas
- `GET /api/v1/validation/errors` - Lista erros de validaÃ§Ã£o
- `GET /api/v1/validation/dashboard` - Dashboard com estatÃ­sticas
- `GET /api/v1/validation/dlq` - Eventos na Dead Letter Queue
- `POST /api/v1/validation/dlq/{id}/retry` - Reprocessar evento DLQ

**DocumentaÃ§Ã£o Swagger:** (Sprint 2)

---

## ğŸ—ºï¸ Roadmap

### âœ… Sprint 1 - Infraestrutura Base (ConcluÃ­da)
- [x] Setup Docker Compose
- [x] Cluster Kafka (3 brokers)
- [x] Producer Service (CDC + Kafka)
- [x] Consumer Service (Validation + Persistence)
- [x] Observabilidade (Prometheus + Grafana)
- [x] DocumentaÃ§Ã£o (C4 + ADRs)

### ğŸ”„ Sprint 2 - Qualidade e Monitoramento (Em Planejamento)
- [ ] Testes unitÃ¡rios Consumer (35+ testes)
- [ ] Testes de integraÃ§Ã£o (Testcontainers)
- [ ] Testes de carga (JMeter)
- [ ] Dashboards Grafana
- [ ] Alertas Prometheus
- [ ] DocumentaÃ§Ã£o Swagger

### ğŸ“‹ Sprint 3 - ProduÃ§Ã£o (Backlog)
- [ ] CI/CD (GitHub Actions)
- [ ] MigraÃ§Ã£o CDC (Debezium)
- [ ] SeguranÃ§a (TLS + SASL)
- [ ] Backup e DR
- [ ] DocumentaÃ§Ã£o deployment
- [ ] Testes E2E

---

## ğŸ¤ ContribuiÃ§Ã£o

Este Ã© um projeto aplicado, mas sugestÃµes sÃ£o bem-vindas!

### Como Contribuir

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add: nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

### PadrÃ£o de Commits

Seguimos [Conventional Commits](https://www.conventionalcommits.org/):

```

feat: adicionar nova funcionalidade
fix: corrigir bug
docs: atualizar documentaÃ§Ã£o
test: adicionar testes
refactor: refatorar cÃ³digo
chore: tarefas de manutenÃ§Ã£o

```

---
## ğŸ“§ Contato

**Aluno:** MÃ¡rcio Kuroki GonÃ§alves  
**Email:** [marciokuroki@gmail.com]  
**GitHub:** [github.com/marciokuroki]

**Orientador:** Reinaldo GalvÃ£o  
**InstituiÃ§Ã£o:** XP EducaÃ§Ã£o  
**Curso:** PÃ³s-GraduaÃ§Ã£o em Arquitetura de Software e SoluÃ§Ãµes

---

## ğŸ“Š EstatÃ­sticas do Projeto

| MÃ©trica | Valor |
|---------|-------|
| Linhas de CÃ³digo | ~8.000 |
| Testes UnitÃ¡rios | 18 (Producer) + 35 (Consumer - Sprint 2) |
| Cobertura | 82% |
| Containers | 14 |
| ServiÃ§os Spring Boot | 2 |
| ADRs Documentados | 5 |
| DuraÃ§Ã£o Sprint 1 | 1 semana |
| Commits | 150+ |